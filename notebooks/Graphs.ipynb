{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624df8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artur\\AppData\\Local\\Temp\\ipykernel_19356\\2005698890.py:18: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv(\"Cleancsv/gamalytics_data.csv\")  # Original 90k dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set style for presentation-quality graphs\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "\n",
    "# Load datasets\n",
    "original_df = pd.read_csv(\"Cleancsv/gamalytics_data.csv\")  # Original 90k dataset\n",
    "filtered_df = pd.read_csv(\"Proyecto_ML.csv\")              # Filtered 7k dataset\n",
    "\n",
    "# Create a flag for games that made it to the filtered dataset\n",
    "original_df['in_filtered_set'] = original_df['Steam Id'].isin(filtered_df['appid']).astype(int)\n",
    "\n",
    "# Distribution Comparison (Copies Sold)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Get data for plotting\n",
    "in_filtered = original_df[original_df['in_filtered_set'] == 1]['Copies Sold'].dropna()\n",
    "not_filtered = original_df[original_df['in_filtered_set'] == 0]['Copies Sold'].dropna()\n",
    "\n",
    "# Cap at 99th percentile for better visualization\n",
    "filtered_max = np.percentile(in_filtered, 99)\n",
    "unfiltered_max = np.percentile(not_filtered, 99)\n",
    "plot_max = max(filtered_max, unfiltered_max)\n",
    "\n",
    "filtered_plot = in_filtered[in_filtered <= plot_max]\n",
    "unfiltered_plot = not_filtered[not_filtered <= plot_max]\n",
    "\n",
    "# Create log-spaced bins\n",
    "bins = np.logspace(np.log10(max(1, min(unfiltered_plot.min(), filtered_plot.min()))), \n",
    "                 np.log10(plot_max), \n",
    "                 50)\n",
    "\n",
    "# Plot histograms\n",
    "plt.hist(unfiltered_plot, bins=bins, color='#4472C4', alpha=0.7, label='Not in Filtered Dataset')\n",
    "plt.hist(filtered_plot, bins=bins, color='#ED7D31', alpha=0.7, label='In Filtered Dataset')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.title('Distribution of Copies Sold (Capped at 99th Percentile)', fontweight='bold')\n",
    "plt.xlabel('Copies Sold (Log Scale)')\n",
    "plt.ylabel('Number of Games')\n",
    "plt.legend(frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"copies_sold_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# CDF Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Sort the data\n",
    "filtered_sorted = np.sort(in_filtered)\n",
    "unfiltered_sorted = np.sort(not_filtered)\n",
    "\n",
    "# Compute CDFs\n",
    "filtered_cdf = np.arange(1, len(filtered_sorted) + 1) / len(filtered_sorted)\n",
    "unfiltered_cdf = np.arange(1, len(unfiltered_sorted) + 1) / len(unfiltered_sorted)\n",
    "\n",
    "# Plot CDFs\n",
    "plt.plot(unfiltered_sorted, unfiltered_cdf, label='Not in Filtered Dataset', \n",
    "         color='#4472C4', linewidth=3)\n",
    "plt.plot(filtered_sorted, filtered_cdf, label='In Filtered Dataset', \n",
    "         color='#ED7D31', linewidth=3)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.title('Cumulative Distribution: Copies Sold', fontweight='bold')\n",
    "plt.xlabel('Copies Sold (Log Scale)')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.legend(loc='lower right', frameon=True)\n",
    "\n",
    "# Add vertical lines at key percentiles\n",
    "for p, label in [(0.25, '25th'), (0.5, '50th'), (0.75, '75th')]:\n",
    "    filtered_val = np.percentile(filtered_sorted, p*100)\n",
    "    unfiltered_val = np.percentile(unfiltered_sorted, p*100)\n",
    "    \n",
    "    plt.axvline(x=filtered_val, color='#ED7D31', linestyle='--', alpha=0.7)\n",
    "    plt.axvline(x=unfiltered_val, color='#4472C4', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add text annotations\n",
    "    plt.text(filtered_val*1.1, p-0.05, f\"{label} percentile: {filtered_val:,.0f}\", \n",
    "             color='#ED7D31', fontweight='bold')\n",
    "    plt.text(unfiltered_val*1.1, p+0.05, f\"{label} percentile: {unfiltered_val:,.0f}\", \n",
    "             color='#4472C4', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"copies_sold_cdf.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d1dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "nodes = [\n",
    "    \"Original Dataset\\n(98,350 games)\",\n",
    "    \"Filter for\\nSingle-player games\",\n",
    "    \"Filter for\\nmin 50 reviews\",\n",
    "    \"Merge with\\nSteam API data\",\n",
    "    \"Handle missing\\nengagement metrics\",\n",
    "    \"Filtered Dataset\\n(7,029 games)\",\n",
    "    \"Feature Engineering\",\n",
    "    \"Train/Test Split\",\n",
    "    \"Model Training\",\n",
    "    \"Evaluation\"\n",
    "]\n",
    "\n",
    "# Define positions manually for better control\n",
    "pos = {\n",
    "    nodes[0]: (0, 0),\n",
    "    nodes[1]: (0, -1),\n",
    "    nodes[2]: (0, -2),\n",
    "    nodes[3]: (0, -3),\n",
    "    nodes[4]: (0, -4),\n",
    "    nodes[5]: (0, -5),\n",
    "    nodes[6]: (1, -5),\n",
    "    nodes[7]: (2, -5),\n",
    "    nodes[8]: (3, -5),\n",
    "    nodes[9]: (4, -5),\n",
    "}\n",
    "\n",
    "# Add nodes with positions\n",
    "for node in nodes:\n",
    "    G.add_node(node)\n",
    "\n",
    "# Add edges\n",
    "edges = [\n",
    "    (nodes[0], nodes[1]),\n",
    "    (nodes[1], nodes[2]),\n",
    "    (nodes[2], nodes[3]),\n",
    "    (nodes[3], nodes[4]),\n",
    "    (nodes[4], nodes[5]),\n",
    "    (nodes[5], nodes[6]),\n",
    "    (nodes[6], nodes[7]),\n",
    "    (nodes[7], nodes[8]),\n",
    "    (nodes[8], nodes[9]),\n",
    "]\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(15, 10))\n",
    "nx.draw_networkx(\n",
    "    G, pos,\n",
    "    node_color=\"#C5E0B4\",\n",
    "    node_size=5000,\n",
    "    font_size=13,\n",
    "    font_weight=\"bold\",\n",
    "    arrowsize=20,\n",
    "    width=2,\n",
    "    edge_color=\"#70AD47\",\n",
    "    arrows=True,\n",
    ")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data_processing_flow.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8f98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Proyecto_ML.csv\")\n",
    "\n",
    "# Correlation Heatmap\n",
    "# Select relevant columns for correlation\n",
    "correlation_cols = [\n",
    "    'time_to_beat', 'Followers', 'engagement_ratio', 'Price', \n",
    "    'Wishlists', 'bayesian_score', 'Copies Sold'\n",
    "]\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df[correlation_cols].corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    mask=mask,\n",
    "    cmap=cmap, \n",
    "    vmax=1, \n",
    "    vmin=-1, \n",
    "    center=0,\n",
    "    square=True, \n",
    "    linewidths=.5, \n",
    "    annot=True, \n",
    "    fmt=\".2f\",\n",
    "    annot_kws={'size': 12},\n",
    "    cbar_kws={\"shrink\": .8}\n",
    ")\n",
    "\n",
    "plt.title('Feature Correlation Heatmap', fontsize=18, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Engagement Metrics Scatter Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Since Publishers Class is already one-hot encoded, we need to create a column that indicates the class\n",
    "publisher_columns = ['Publishers Class_AA', 'Publishers Class_AAA', \n",
    "                    'Publishers Class_Hobbyist', 'Publishers Class_Indie']\n",
    "\n",
    "# Create a temporary column that indicates the publisher class\n",
    "df['temp_publisher_class'] = 'Unknown'\n",
    "for col in publisher_columns:\n",
    "    class_name = col.replace('Publishers Class_', '')\n",
    "    df.loc[df[col] == 1, 'temp_publisher_class'] = class_name\n",
    "\n",
    "# Create a publisher class color map\n",
    "color_map = {\n",
    "    'AAA': '#FF6B6B', \n",
    "    'AA': '#4ECDC4', \n",
    "    'Indie': '#45B7D1',\n",
    "    'Hobbyist': '#98D560',\n",
    "    'Unknown': '#999999'\n",
    "}\n",
    "\n",
    "# Create scatter plot\n",
    "for pub_class in df['temp_publisher_class'].unique():\n",
    "    subset = df[df['temp_publisher_class'] == pub_class]\n",
    "    plt.scatter(\n",
    "        subset['time_to_beat'], \n",
    "        subset['average_playtime_forever'] / 60 if 'average_playtime_forever' in df.columns else subset['time_to_beat'],  # Fallback if column doesn't exist\n",
    "        alpha=0.7,\n",
    "        label=pub_class,\n",
    "        color=color_map.get(pub_class, '#999999'),\n",
    "        s=60,\n",
    "        edgecolor='w',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "\n",
    "# Add reference lines for engagement ratios\n",
    "max_time = df['time_to_beat'].max() * 1.1\n",
    "x = np.linspace(0, max_time, 100)\n",
    "\n",
    "for ratio, style in [(0.5, '--'), (1.0, '-'), (2.0, '--'), (5.0, ':')]:\n",
    "    plt.plot(x, ratio * x, linestyle=style, color='#888888', alpha=0.7, \n",
    "             label=f'Engagement Ratio = {ratio}')\n",
    "\n",
    "plt.xlabel('Time to Beat (hours)')\n",
    "plt.ylabel('Average Playtime (hours)')\n",
    "plt.title('Relationship Between Game Length and Player Engagement', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(frameon=True)\n",
    "\n",
    "# Set reasonable axis limits\n",
    "plt.xlim(0, min(100, df['time_to_beat'].quantile(0.95)))\n",
    "\n",
    "# Make sure we have the average_playtime_forever column, otherwise use time_to_beat\n",
    "if 'average_playtime_forever' in df.columns:\n",
    "    plt.ylim(0, min(200, (df['average_playtime_forever'] / 60).quantile(0.95)))\n",
    "else:\n",
    "    # Fallback to a reasonable multiple of time_to_beat\n",
    "    plt.ylim(0, min(200, df['time_to_beat'].quantile(0.95) * 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"engagement_scatter.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Clean up the temporary column\n",
    "df = df.drop('temp_publisher_class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a76448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"catboost_model_Copies Sold.pkl\")\n",
    "\n",
    "# Feature importance visualization\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': model.feature_names_,\n",
    "    'Importance': model.get_feature_importance()\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "# Define color map by feature type\n",
    "def get_feature_color(feature_name):\n",
    "    if feature_name.startswith('Tags_'):\n",
    "        return '#5B9BD5'  # Blue for Tags\n",
    "    elif feature_name.startswith('genres_'):\n",
    "        return '#ED7D31'  # Orange for Genres\n",
    "    elif feature_name.startswith('categories_'):\n",
    "        return '#A5A5A5'  # Gray for Categories\n",
    "    elif feature_name.startswith('Publishers Class_'):\n",
    "        return '#FFC000'  # Yellow for Publisher Class\n",
    "    else:\n",
    "        return '#70AD47'  # Green for other features\n",
    "\n",
    "# Map colors to features\n",
    "feature_colors = [get_feature_color(feature) for feature in feature_importance['Feature']]\n",
    "\n",
    "# Create horizontal bar chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "bars = plt.barh(\n",
    "    feature_importance['Feature'],\n",
    "    feature_importance['Importance'],\n",
    "    color=feature_colors,\n",
    "    edgecolor='white',\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "# Add value labels to the right of each bar\n",
    "for i, (importance, feature) in enumerate(zip(feature_importance['Importance'], feature_importance['Feature'])):\n",
    "    plt.text(\n",
    "        importance + importance * 0.01,\n",
    "        i,\n",
    "        f\"{importance:.4f}\",\n",
    "        va='center',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for Copies Sold Prediction', fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a legend for feature types\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#5B9BD5', label='Tags'),\n",
    "    Patch(facecolor='#ED7D31', label='Genres'),\n",
    "    Patch(facecolor='#A5A5A5', label='Categories'),\n",
    "    Patch(facecolor='#FFC000', label='Publisher Class'),\n",
    "    Patch(facecolor='#70AD47', label='Other Features')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.savefig(\"feature_importance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2596fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a visual representation of percentile differences\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Define the percentiles to visualize\n",
    "percentiles = [25, 50, 75]\n",
    "\n",
    "# Data for Copies Sold - from your analysis\n",
    "not_filtered_values = [55, 390, 2607]\n",
    "filtered_values = [11085, 32976, 133840]\n",
    "ratios = [filtered_values[i]/not_filtered_values[i] for i in range(len(percentiles))]\n",
    "\n",
    "# Create positions on x-axis\n",
    "x = np.arange(len(percentiles))\n",
    "width = 0.35\n",
    "\n",
    "# Create the grouped bar chart\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "# Plot bars\n",
    "bars1 = ax.bar(x - width/2, not_filtered_values, width, label='Not Filtered', color='#4472C4')\n",
    "bars2 = ax.bar(x + width/2, filtered_values, width, label='Filtered', color='#ED7D31')\n",
    "\n",
    "# Add labels\n",
    "ax.set_ylabel('Copies Sold', fontsize=14)\n",
    "ax.set_title('Comparison of Copies Sold Percentiles', fontweight='bold', fontsize=16)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{p}th Percentile' for p in percentiles])\n",
    "ax.legend()\n",
    "\n",
    "# Use log scale for y-axis\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add value annotations and ratio text\n",
    "for i, (bar1, bar2, ratio) in enumerate(zip(bars1, bars2, ratios)):\n",
    "    # Format values differently based on magnitude\n",
    "    if bar1.get_height() < 1000:\n",
    "        height1_text = f\"{bar1.get_height():.0f}\"\n",
    "    else:\n",
    "        height1_text = f\"{bar1.get_height():,.0f}\"\n",
    "        \n",
    "    if bar2.get_height() < 1000:\n",
    "        height2_text = f\"{bar2.get_height():.0f}\"\n",
    "    else:\n",
    "        height2_text = f\"{bar2.get_height():,.0f}\"\n",
    "    \n",
    "    # Add text for non-filtered dataset\n",
    "    ax.text(bar1.get_x() + bar1.get_width()/2, bar1.get_height()*1.1,\n",
    "            height1_text, ha='center', va='bottom', color='#4472C4', fontweight='bold')\n",
    "    \n",
    "    # Add text for filtered dataset\n",
    "    ax.text(bar2.get_x() + bar2.get_width()/2, bar2.get_height()*1.1,\n",
    "            height2_text, ha='center', va='bottom', color='#ED7D31', fontweight='bold')\n",
    "    \n",
    "    # Add ratio text between bars\n",
    "    y_pos = np.sqrt(bar1.get_height() * bar2.get_height())  # Geometric mean for positioning\n",
    "    ax.text(i, y_pos, f\"{ratio:.1f}x\", ha='center', va='center', \n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", fc='#FFF2CC', ec='#FFD966'),\n",
    "           fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"percentile_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b813446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "\n",
    "# Create a visual representation of the two-stage model architecture\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Define colors\n",
    "color_stage1 = '#5B9BD5'  # Blue\n",
    "color_stage2 = '#ED7D31'  # Orange\n",
    "color_input = '#70AD47'   # Green\n",
    "color_output = '#FFC000'  # Yellow\n",
    "color_arrow = '#A5A5A5'   # Gray\n",
    "\n",
    "# Function to create boxes with rounded corners\n",
    "def create_box(x, y, width, height, color, label, fontsize=12, fontweight='normal'):\n",
    "    rect = patches.FancyBboxPatch(\n",
    "        (x, y), width, height, \n",
    "        linewidth=2, \n",
    "        edgecolor='black',\n",
    "        facecolor=color, \n",
    "        alpha=0.7, \n",
    "        zorder=2,\n",
    "        boxstyle=patches.BoxStyle.Round(pad=0.3)\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + width/2, y + height/2, label, ha='center', va='center', \n",
    "            fontsize=fontsize, fontweight=fontweight, zorder=3)\n",
    "    return rect\n",
    "\n",
    "# Function to create arrows\n",
    "def create_arrow(start_x, start_y, end_x, end_y, color, label=None, label_pos=0.5):\n",
    "    arrow = patches.FancyArrowPatch((start_x, start_y), (end_x, end_y),\n",
    "                                  connectionstyle=\"arc3,rad=0\", \n",
    "                                  arrowstyle='-|>', linewidth=2,\n",
    "                                  color=color, zorder=1)\n",
    "    ax.add_patch(arrow)\n",
    "    \n",
    "    if label:\n",
    "        # Position the label along the arrow\n",
    "        mid_x = start_x + label_pos * (end_x - start_x)\n",
    "        mid_y = start_y + label_pos * (end_y - start_y)\n",
    "        \n",
    "        ax.text(mid_x, mid_y, label, ha='center', va='center',\n",
    "                fontsize=10, backgroundcolor='white', zorder=3)\n",
    "\n",
    "# Create input box\n",
    "create_box(1, 9, 3, 1, color_input, \"Game Features\\n(500+ characteristics)\",\n",
    "          fontsize=12, fontweight='bold')\n",
    "\n",
    "# Create Stage 1 boxes\n",
    "create_box(1, 6, 3, 1.5, color_stage1, \"STAGE 1\\nClassification Model\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "create_box(1, 4.5, 3, 1, color_stage1, \"Will game be in top 7%?\",\n",
    "          fontsize=12)\n",
    "\n",
    "# Create conditional branching\n",
    "create_box(0, 3, 1.5, 1, color_stage1, \"No\", fontsize=12)\n",
    "create_box(3.5, 3, 1.5, 1, color_stage1, \"Yes\", fontsize=12)\n",
    "\n",
    "# Create Stage 2 box\n",
    "create_box(3, 1.5, 3, 1, color_stage2, \"STAGE 2\\nRegression Model\",\n",
    "          fontsize=14, fontweight='bold')\n",
    "\n",
    "# Create output boxes\n",
    "create_box(0, 0.5, 2, 1, color_output, \"General Market\\nPrediction\", fontsize=12)\n",
    "create_box(3, 0, 3, 1, color_output, \"Precise Metrics:\\nCopies Sold, Wishlists, Score\", fontsize=12)\n",
    "\n",
    "# Create connections\n",
    "create_arrow(2.5, 9, 2.5, 7.5, color_arrow)\n",
    "create_arrow(2.5, 6, 2.5, 5.5, color_arrow)\n",
    "create_arrow(2.5, 4.5, 2.5, 4, color_arrow)\n",
    "\n",
    "# Branching arrows\n",
    "create_arrow(2.5, 4, 0.75, 3, color_arrow)\n",
    "create_arrow(2.5, 4, 4.25, 3, color_arrow)\n",
    "\n",
    "# Final arrows\n",
    "create_arrow(0.75, 3, 1, 1.5, color_arrow)\n",
    "create_arrow(4.25, 3, 4.5, 2.5, color_arrow)\n",
    "\n",
    "# Output arrows\n",
    "create_arrow(1, 1.5, 1, 0.5, color_arrow)\n",
    "create_arrow(4.5, 2.5, 4.5, 1, color_arrow)\n",
    "\n",
    "# Title\n",
    "plt.text(3.5, 10.5, 'Two-Stage Model Architecture', ha='center', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Explanation text\n",
    "explanation = (\n",
    "    \"This approach addresses dataset bias by first classifying if a game\\n\"\n",
    "    \"will be successful enough to have engagement metrics (Stage 1),\\n\"\n",
    "    \"then predicting specific performance metrics only for likely\\n\"\n",
    "    \"successful games (Stage 2).\"\n",
    ")\n",
    "plt.text(7, 5, explanation, ha='left', va='center', fontsize=12,\n",
    "        bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))\n",
    "\n",
    "# Set limits and turn off axis\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 11)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"two_stage_model.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7faa5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artur\\AppData\\Local\\Temp\\ipykernel_19356\\233659633.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv(\"Cleancsv/gamalytics_data.csv\")  # Original 90k dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Metric     Dataset  Minimum   Median      Maximum\n",
      "0   Copies Sold    Filtered    563.0  32976.0   52847649.0\n",
      "1   Copies Sold  Unfiltered      0.0    390.0  302975930.0\n",
      "2     Wishlists    Filtered    204.0  16500.0    4673900.0\n",
      "3     Wishlists  Unfiltered     12.0   1100.0    5926800.0\n",
      "4  Review Score    Filtered      0.0     84.0        100.0\n",
      "5  Review Score  Unfiltered      0.0     80.0        100.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Figure object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 227\u001b[39m\n\u001b[32m    224\u001b[39m plt.close()\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# Create a table with the actual values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m fig, ax = plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m), constrained_layout=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    228\u001b[39m ax = plt.subplot(\u001b[32m111\u001b[39m)\n\u001b[32m    229\u001b[39m ax.axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable Figure object"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load datasets\n",
    "original_df = pd.read_csv(\"Cleancsv/gamalytics_data.csv\")  # Original 90k dataset \n",
    "filtered_df = pd.read_csv(\"Proyecto_ML.csv\")               # Filtered 7k dataset\n",
    "\n",
    "# Create a flag for games that made it to the filtered dataset\n",
    "original_df['in_filtered_set'] = original_df['Steam Id'].isin(filtered_df['appid']).astype(int)\n",
    "\n",
    "# Define the metrics to visualize\n",
    "metrics = [\"Copies Sold\", \"Wishlists\", \"Review Score\"]  # Using Review Score instead of bayesian_score if it's available\n",
    "\n",
    "# Create a dataframe to store min/max values\n",
    "results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    if metric in original_df.columns:\n",
    "        # Calculate statistics for filtered set\n",
    "        filtered_data = original_df[original_df['in_filtered_set'] == 1][metric].dropna()\n",
    "        filtered_min = filtered_data.min()\n",
    "        filtered_max = filtered_data.max()\n",
    "        filtered_median = filtered_data.median()\n",
    "        \n",
    "        # Calculate statistics for unfiltered set\n",
    "        unfiltered_data = original_df[original_df['in_filtered_set'] == 0][metric].dropna()\n",
    "        unfiltered_min = unfiltered_data.min()\n",
    "        unfiltered_max = unfiltered_data.max()\n",
    "        unfiltered_median = unfiltered_data.median()\n",
    "        \n",
    "        # Add to results\n",
    "        results.append({\n",
    "            'Metric': metric,\n",
    "            'Dataset': 'Filtered',\n",
    "            'Minimum': filtered_min,\n",
    "            'Median': filtered_median,\n",
    "            'Maximum': filtered_max\n",
    "        })\n",
    "        \n",
    "        results.append({\n",
    "            'Metric': metric,\n",
    "            'Dataset': 'Unfiltered',\n",
    "            'Minimum': unfiltered_min,\n",
    "            'Median': unfiltered_median,\n",
    "            'Maximum': unfiltered_max\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results table\n",
    "print(results_df)\n",
    "\n",
    "# Create separate visualizations for each metric to handle different scales better\n",
    "for metric in metrics:\n",
    "    if metric not in original_df.columns:\n",
    "        continue\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract data for this metric\n",
    "    metric_data = results_df[results_df['Metric'] == metric]\n",
    "    \n",
    "    # Create positions for the bars\n",
    "    x = np.arange(3)  # min, median, max\n",
    "    width = 0.35\n",
    "    \n",
    "    # Get filtered and unfiltered data\n",
    "    filtered = metric_data[metric_data['Dataset'] == 'Filtered']\n",
    "    unfiltered = metric_data[metric_data['Dataset'] == 'Unfiltered']\n",
    "    \n",
    "    # Extract the values\n",
    "    filtered_values = [filtered['Minimum'].values[0], filtered['Median'].values[0], filtered['Maximum'].values[0]]\n",
    "    unfiltered_values = [unfiltered['Minimum'].values[0], unfiltered['Median'].values[0], unfiltered['Maximum'].values[0]]\n",
    "    \n",
    "    # Check if we need log scale\n",
    "    use_log_scale = (metric in [\"Copies Sold\", \"Wishlists\"])\n",
    "    \n",
    "    # For Review Score, calculate min values as percentage of max\n",
    "    if metric == \"Review Score\":\n",
    "        # Use linear scale for Review Score\n",
    "        use_log_scale = False\n",
    "        # Ensure minimum values are clearly visible with a linear scale\n",
    "        bars1 = plt.bar(x - width/2, filtered_values, width, label='Filtered Dataset (7k games)', color='#ED7D31')\n",
    "        bars2 = plt.bar(x + width/2, unfiltered_values, width, label='Unfiltered Dataset (90k games)', color='#4472C4')\n",
    "    else:\n",
    "        # For metrics with large ranges, use log scale\n",
    "        if use_log_scale:\n",
    "            # Add a small offset to zero values for log scale\n",
    "            filtered_values = [max(0.1, val) for val in filtered_values]\n",
    "            unfiltered_values = [max(0.1, val) for val in unfiltered_values]\n",
    "            plt.yscale('log')\n",
    "        \n",
    "        bars1 = plt.bar(x - width/2, filtered_values, width, label='Filtered Dataset (7k games)', color='#ED7D31')\n",
    "        bars2 = plt.bar(x + width/2, unfiltered_values, width, label='Unfiltered Dataset (90k games)', color='#4472C4')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title(f'{metric} Range Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.xticks(x, ['Minimum', 'Median', 'Maximum'], fontsize=14)\n",
    "    plt.ylabel(metric, fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Add value labels to the bars\n",
    "    def add_value_labels(bars, values):\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            if metric in [\"Copies Sold\", \"Wishlists\"]:\n",
    "                if value >= 1000000:\n",
    "                    label = f'{value/1000000:.1f}M'\n",
    "                elif value >= 1000:\n",
    "                    label = f'{value/1000:.1f}K'\n",
    "                else:\n",
    "                    label = f'{value:.1f}'\n",
    "            else:\n",
    "                label = f'{value:.1f}'\n",
    "                \n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height * 1.05,\n",
    "                    label, ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Add value labels for both bar sets\n",
    "    add_value_labels(bars1, filtered_values)  # Filtered dataset\n",
    "    add_value_labels(bars2, unfiltered_values)  # Unfiltered dataset\n",
    "    \n",
    "    # Add a subtitle with the ratio info\n",
    "    min_ratio = filtered['Minimum'].values[0] / max(1, unfiltered['Minimum'].values[0])\n",
    "    median_ratio = filtered['Median'].values[0] / max(1, unfiltered['Median'].values[0])\n",
    "    max_ratio = filtered['Maximum'].values[0] / max(1, unfiltered['Maximum'].values[0])\n",
    "    \n",
    "    subtitle = f\"Ratios (Filtered/Unfiltered): Minimum: {min_ratio:.1f}x  |  Median: {median_ratio:.1f}x  |  Maximum: {max_ratio:.1f}x\"\n",
    "    plt.figtext(0.5, 0.01, subtitle, ha='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)  # Make room for the subtitle\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f'{metric.replace(\" \", \"_\")}_range_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Create a combined visualization with all metrics in separate subplots\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    if metric not in original_df.columns:\n",
    "        continue\n",
    "        \n",
    "    plt.subplot(len(metrics), 1, i+1)\n",
    "    \n",
    "    # Extract data for this metric\n",
    "    metric_data = results_df[results_df['Metric'] == metric]\n",
    "    \n",
    "    # Create positions for the bars\n",
    "    x = np.arange(3)  # min, median, max\n",
    "    width = 0.35\n",
    "    \n",
    "    # Get filtered and unfiltered data\n",
    "    filtered = metric_data[metric_data['Dataset'] == 'Filtered']\n",
    "    unfiltered = metric_data[metric_data['Dataset'] == 'Unfiltered']\n",
    "    \n",
    "    # Extract the values\n",
    "    filtered_values = [filtered['Minimum'].values[0], filtered['Median'].values[0], filtered['Maximum'].values[0]]\n",
    "    unfiltered_values = [unfiltered['Minimum'].values[0], unfiltered['Median'].values[0], unfiltered['Maximum'].values[0]]\n",
    "    \n",
    "    # For metrics with large ranges, use log scale\n",
    "    if metric in [\"Copies Sold\", \"Wishlists\"]:\n",
    "        # Add a small offset to zero values for log scale\n",
    "        filtered_values = [max(0.1, val) for val in filtered_values]\n",
    "        unfiltered_values = [max(0.1, val) for val in unfiltered_values]\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    # Create the bars\n",
    "    bars1 = plt.bar(x - width/2, filtered_values, width, label='Filtered Dataset (7k games)', color='#ED7D31')\n",
    "    bars2 = plt.bar(x + width/2, unfiltered_values, width, label='Unfiltered Dataset (90k games)', color='#4472C4')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title(f'{metric} Range Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.xticks(x, ['Minimum', 'Median', 'Maximum'], fontsize=14)\n",
    "    plt.ylabel(metric, fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Only add legend to the first subplot\n",
    "    if i == 0:\n",
    "        plt.legend(fontsize=12)\n",
    "    \n",
    "    # Add value labels to the bars\n",
    "    def add_value_labels(bars, values):\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            if metric in [\"Copies Sold\", \"Wishlists\"]:\n",
    "                if value >= 1000000:\n",
    "                    label = f'{value/1000000:.1f}M'\n",
    "                elif value >= 1000:\n",
    "                    label = f'{value/1000:.1f}K'\n",
    "                else:\n",
    "                    label = f'{value:.1f}'\n",
    "            else:\n",
    "                label = f'{value:.1f}'\n",
    "                \n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height * 1.05,\n",
    "                    label, ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Add value labels for both bar sets\n",
    "    add_value_labels(bars1, filtered_values)  # Filtered dataset\n",
    "    add_value_labels(bars2, unfiltered_values)  # Unfiltered dataset\n",
    "\n",
    "# Add overall title\n",
    "plt.suptitle('Dataset Range Comparison: Filtered vs. Unfiltered', \n",
    "             fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "# Add explanation text\n",
    "explanation = (\n",
    "    \"This visualization illustrates the extreme difference in value ranges between the filtered dataset (7,029 games) \"\n",
    "    \"and the unfiltered dataset (90,000+ games). Note that even the minimum values in the filtered dataset are \"\n",
    "    \"substantially higher than typical values in the unfiltered dataset, demonstrating the need for a two-model \"\n",
    "    \"approach to accurately handle the full spectrum of games.\"\n",
    ")\n",
    "\n",
    "plt.figtext(0.5, 0.01, explanation, wrap=True, horizontalalignment='center', fontsize=14)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.4, bottom=0.1)\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig('dataset_range_comparison_combined.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Create a table with the actual values\n",
    "fig, ax = plt.figure(figsize=(12, 6), constrained_layout=True)\n",
    "ax = plt.subplot(111)\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table data\n",
    "table_data = []\n",
    "headers = ['Metric', 'Dataset', 'Minimum', 'Median', 'Maximum', 'Min Ratio', 'Med Ratio', 'Max Ratio']\n",
    "for metric in metrics:\n",
    "    if metric not in original_df.columns:\n",
    "        continue\n",
    "        \n",
    "    # Extract data for this metric\n",
    "    metric_data = results_df[results_df['Metric'] == metric]\n",
    "    \n",
    "    # Get filtered and unfiltered data\n",
    "    filtered = metric_data[metric_data['Dataset'] == 'Filtered']\n",
    "    unfiltered = metric_data[metric_data['Dataset'] == 'Unfiltered']\n",
    "    \n",
    "    # Calculate ratios\n",
    "    min_ratio = filtered['Minimum'].values[0] / max(1, unfiltered['Minimum'].values[0])\n",
    "    median_ratio = filtered['Median'].values[0] / max(1, unfiltered['Median'].values[0])\n",
    "    max_ratio = filtered['Maximum'].values[0] / max(1, unfiltered['Maximum'].values[0])\n",
    "    \n",
    "    # Format the values\n",
    "    if metric in [\"Copies Sold\", \"Wishlists\"]:\n",
    "        f_min = f\"{filtered['Minimum'].values[0]:,.0f}\"\n",
    "        f_med = f\"{filtered['Median'].values[0]:,.0f}\" \n",
    "        f_max = f\"{filtered['Maximum'].values[0]:,.0f}\"\n",
    "        u_min = f\"{unfiltered['Minimum'].values[0]:,.0f}\"\n",
    "        u_med = f\"{unfiltered['Median'].values[0]:,.0f}\"\n",
    "        u_max = f\"{unfiltered['Maximum'].values[0]:,.0f}\"\n",
    "    else:\n",
    "        f_min = f\"{filtered['Minimum'].values[0]:.1f}\"\n",
    "        f_med = f\"{filtered['Median'].values[0]:.1f}\"\n",
    "        f_max = f\"{filtered['Maximum'].values[0]:.1f}\"\n",
    "        u_min = f\"{unfiltered['Minimum'].values[0]:.1f}\"\n",
    "        u_med = f\"{unfiltered['Median'].values[0]:.1f}\"\n",
    "        u_max = f\"{unfiltered['Maximum'].values[0]:.1f}\"\n",
    "    \n",
    "    # Add to table data\n",
    "    table_data.append([metric, 'Filtered', f_min, f_med, f_max, '', '', ''])\n",
    "    table_data.append([metric, 'Unfiltered', u_min, u_med, u_max, f\"{min_ratio:.1f}x\", f\"{median_ratio:.1f}x\", f\"{max_ratio:.1f}x\"])\n",
    "\n",
    "# Create the table\n",
    "table = plt.table(cellText=table_data,\n",
    "          colLabels=headers,\n",
    "          loc='center',\n",
    "          cellLoc='center',\n",
    "          colWidths=[0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12])\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# Color the header row\n",
    "for i, key in enumerate(headers):\n",
    "    table[(0, i)].set_facecolor('#4472C4')\n",
    "    table[(0, i)].set_text_props(color='white', fontweight='bold')\n",
    "\n",
    "# Color the ratio cells\n",
    "for row in range(len(table_data)):\n",
    "    if row % 2 == 1:  # Unfiltered rows\n",
    "        for col in range(5, 8):  # Ratio columns\n",
    "            table[(row+1, col)].set_facecolor('#FFC000')\n",
    "            table[(row+1, col)].set_text_props(fontweight='bold')\n",
    "\n",
    "plt.title('Dataset Value Comparison: Filtered vs. Unfiltered', fontsize=16, fontweight='bold')\n",
    "plt.savefig('dataset_value_table.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa5c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
